{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kleiofragkedaki/miniconda3/envs/rl_thesis_2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pprint as pp\n",
    "\n",
    "from src.options import get_options\n",
    "from src.utils import load_env\n",
    "from src.agents import Agent\n",
    "from src.utils.hyperparameter_config import config\n",
    "\n",
    "import ray\n",
    "from ray import tune, air\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.air import session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config: dict()):\n",
    "    # Pretty print the run args\n",
    "    config[\"output_dir\"] = \"runs\"\n",
    "    # config[\"problem\"] = \"tsp\"\n",
    "    # config[\"epoch_size\"] = 16\n",
    "    # config[\"val_size\"] = 16\n",
    "    # config[\"batch_size\"] = 16\n",
    "    # config[\"eval_batch_size\"] = 16\n",
    "    # config[\"n_epochs\"] = 2\n",
    "    args_list = [f\"--{k}={v}\" for k, v in config.items()]\n",
    "    args_list.append(\"--no_tensorboard\")\n",
    "    args_list.append(\"--no_cuda\")\n",
    "    opts = get_options(args_list)\n",
    "\n",
    "    pp.pprint(vars(opts))\n",
    "\n",
    "    # Set the random seed\n",
    "    torch.manual_seed(opts.seed)\n",
    "\n",
    "    # Initialize the Environment\n",
    "    env = load_env(opts.problem)\n",
    "\n",
    "    # Train the Agent\n",
    "    agent = Agent(opts, env, session)\n",
    "    agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 03:48:13,679\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "/Users/kleiofragkedaki/miniconda3/envs/rl_thesis_2023/lib/python3.9/site-packages/ray/air/config.py:799: UserWarning: Setting a `RunConfig.local_dir` is deprecated and will be removed in the future. If you are not using remote storage,set the `RunConfig.storage_path` instead. Otherwise, set the`RAY_AIR_LOCAL_CACHE_DIR` environment variable to control the local cache location.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-19 03:48:37</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:23.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.6/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/5 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th>hyperparameter_tunin\n",
       "g     </th><th style=\"text-align: right;\">   lr_model</th><th style=\"text-align: right;\">  n_encode_layers</th><th style=\"text-align: right;\">  n_epochs</th><th>optimizer_class  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>run_984d8b74</td><td>TERMINATED</td><td>127.0.0.1:69934</td><td style=\"text-align: right;\">         512</td><td>True</td><td style=\"text-align: right;\">0.000499017</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">        30</td><td>Adam             </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.6087 </td><td style=\"text-align: right;\">2.40595</td></tr>\n",
       "<tr><td>run_903cbd52</td><td>TERMINATED</td><td>127.0.0.1:69944</td><td style=\"text-align: right;\">         512</td><td>True</td><td style=\"text-align: right;\">0.00050903 </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">       118</td><td>Adam             </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.5658 </td><td style=\"text-align: right;\">2.40595</td></tr>\n",
       "<tr><td>run_7fa8e274</td><td>TERMINATED</td><td>127.0.0.1:69958</td><td style=\"text-align: right;\">         128</td><td>True</td><td style=\"text-align: right;\">8.10994e-05</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">       125</td><td>Adam             </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         9.85945</td><td style=\"text-align: right;\">2.46589</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m {'baseline': 'rollout',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'batch_size': 16,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'battery_limit': 0.6,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'bl_alpha': 0.05,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'bl_warmup_epochs': 1,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'checkpoint_encoder': False,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'checkpoint_epochs': 1,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'dataParallel': False,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'data_distribution': None,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'device': device(type='cpu'),\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'display_graphs': None,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'early_stopping_delta': 10.0,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'early_stopping_patience': 5,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'epoch_size': 16,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'epoch_start': 0,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'eval_batch_size': 16,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'eval_only': False,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'exp_beta': 0.8,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'graph_size': 5,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'hidden_dim': 512,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'load_path': None,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'log_step': 5,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'lr_model': 0.0004990169467384537,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'max_grad_norm': 1.0,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'n_encode_layers': 4,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'n_epochs': 2,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'no_cuda': True,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'no_progress_bar': False,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'no_tensorboard': True,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'normalization': 'batch',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'num_trailers': 4,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'num_trucks': 2,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'optimizer_class': 'Adam',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'output_dir': 'runs',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'problem': 'tsp',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'resume': None,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'run_name': 'rollout_20230719T034818',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'save_dir': '/Users/kleiofragkedaki/Desktop/thesis/master-thesis-2023-reinforcement-learning-in-grids/runs/tsp_5/rollout_20230719T034818',\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'seed': 1234,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'tanh_clipping': 10.0,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'truck_names': None,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'val_dataset': None,\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m  'val_size': 16}\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Evaluating baseline model on evaluation dataset\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Start train epoch 0, lr=0.0004990169467384537 for run rollout_20230719T034818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 141.18it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m epoch: 0, train_batch_id: 0, avg_cost: 2.60872745513916\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m grad_norm: 17.145753860473633, clipped: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Finished epoch 0, took 00:00:05 s\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.04s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name  </th><th>date               </th><th>done  </th><th>experiment_tag                                                                                                 </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>run_7fa8e274</td><td>2023-07-19_03-48-37</td><td>True  </td><td>3_batch_size=128,hyperparameter_tuning=True,lr_model=0.0001,n_encode_layers=3,n_epochs=125,optimizer_class=Adam</td><td>Kleios-MBP</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">2.46589</td><td>127.0.0.1</td><td style=\"text-align: right;\">69958</td><td style=\"text-align: right;\">             9.85945</td><td style=\"text-align: right;\">           4.8465 </td><td style=\"text-align: right;\">       9.85945</td><td style=\"text-align: right;\"> 1689731317</td><td style=\"text-align: right;\">                   2</td><td>7fa8e274  </td></tr>\n",
       "<tr><td>run_903cbd52</td><td>2023-07-19_03-48-33</td><td>True  </td><td>2_batch_size=512,hyperparameter_tuning=True,lr_model=0.0005,n_encode_layers=4,n_epochs=118,optimizer_class=Adam</td><td>Kleios-MBP</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">2.40595</td><td>127.0.0.1</td><td style=\"text-align: right;\">69944</td><td style=\"text-align: right;\">            10.5658 </td><td style=\"text-align: right;\">           5.07756</td><td style=\"text-align: right;\">      10.5658 </td><td style=\"text-align: right;\"> 1689731313</td><td style=\"text-align: right;\">                   2</td><td>903cbd52  </td></tr>\n",
       "<tr><td>run_984d8b74</td><td>2023-07-19_03-48-28</td><td>True  </td><td>1_batch_size=512,hyperparameter_tuning=True,lr_model=0.0005,n_encode_layers=4,n_epochs=30,optimizer_class=Adam </td><td>Kleios-MBP</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">2.40595</td><td>127.0.0.1</td><td style=\"text-align: right;\">69934</td><td style=\"text-align: right;\">            10.6087 </td><td style=\"text-align: right;\">           5.48884</td><td style=\"text-align: right;\">      10.6087 </td><td style=\"text-align: right;\"> 1689731308</td><td style=\"text-align: right;\">                   2</td><td>984d8b74  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Validating...\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Validation overall avg_cost: 2.463257312774658 +- 0.18309058248996735\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Evaluating candidate model on evaluation dataset\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Epoch 0 candidate mean 2.518484354019165, baseline epoch 0 mean 2.4411473274230957, difference 0.07733702659606934\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Set warmup alpha = 1.0\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Start train epoch 1, lr=0.0004990169467384537 for run rollout_20230719T034818\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Evaluating baseline on dataset...\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m {'baseline': 'rollout',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'batch_size': 16,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'battery_limit': 0.6,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'bl_alpha': 0.05,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'bl_warmup_epochs': 1,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'checkpoint_encoder': False,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'checkpoint_epochs': 1,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'dataParallel': False,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'data_distribution': None,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'device': device(type='cpu'),\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'display_graphs': None,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'early_stopping_delta': 10.0,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'early_stopping_patience': 5,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'embedding_dim': 128,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'epoch_size': 16,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'epoch_start': 0,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'eval_batch_size': 16,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'eval_only': False,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'exp_beta': 0.8,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'graph_size': 5,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'hidden_dim': 512,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'hyperparameter_tuning': True,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'load_path': None,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'log_step': 5,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'lr_decay': 1.0,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'lr_model': 8.109936155977077e-05,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'max_grad_norm': 1.0,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'n_encode_layers': 3,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'n_epochs': 2,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'no_cuda': True,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'no_progress_bar': False,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'no_tensorboard': True,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'normalization': 'batch',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'num_trailers': 4,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'num_trucks': 2,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'optimizer_class': 'Adam',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'output_dir': 'runs',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'problem': 'tsp',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'resume': None,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'run_name': 'rollout_20230719T034827',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'save_dir': '/Users/kleiofragkedaki/Desktop/thesis/master-thesis-2023-reinforcement-learning-in-grids/runs/tsp_5/rollout_20230719T034827',\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'seed': 1234,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'tanh_clipping': 10.0,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'truck_names': None,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'val_dataset': None,\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m  'val_size': 16}\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Evaluating baseline model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Evaluating baseline on dataset...\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Evaluating baseline on dataset...\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Finished epoch 1, took 00:00:05 s\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Saving model and state...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Validating...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Validation overall avg_cost: 2.405951499938965 +- 0.12876993417739868\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Evaluating candidate model on evaluation dataset\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m Epoch 1 candidate mean 2.4411473274230957, baseline epoch 0 mean 2.4411473274230957, difference 0.0\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Epoch 1 candidate mean 2.4411473274230957, baseline epoch 0 mean 2.4411473274230957, difference 0.0\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Start train epoch 1, lr=0.0005090303763828512 for run rollout_20230719T034822\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69944)\u001b[0m Epoch 1 candidate mean 2.4411473274230957, baseline epoch 0 mean 2.4411473274230957, difference 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 235.89it/s]\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m /Users/kleiofragkedaki/miniconda3/envs/rl_thesis_2023/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(run pid=69934)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m epoch: 0, train_batch_id: 0, avg_cost: 2.5773630142211914\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m grad_norm: 25.235061645507812, clipped: 1.0\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m p-value: 0.11460422181120809\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Set warmup alpha = 1.0\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00, 252.21it/s]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n",
      "2023-07-19 03:48:37,451\tINFO tune.py:1111 -- Total run time: 23.41 seconds (23.40 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m /Users/kleiofragkedaki/miniconda3/envs/rl_thesis_2023/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m p-value: 0.1450604741367071\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Finished epoch 1, took 00:00:04 s\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Saving model and state...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Validating...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Validation overall avg_cost: 2.465888261795044 +- 0.1560748815536499\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Evaluating candidate model on evaluation dataset\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m Epoch 1 candidate mean 2.485405921936035, baseline epoch 0 mean 2.606360912322998, difference -0.12095499038696289\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(run pid=69958)\u001b[0m p-value: 0.1450604741367071\n"
     ]
    }
   ],
   "source": [
    "N_ITER = 3\n",
    "ray.init(num_cpus=5)\n",
    "searcher = HyperOptSearch(\n",
    "    space=config, metric=\"loss\", mode=\"min\", n_initial_points=int(N_ITER / 10)\n",
    ")\n",
    "algo = ConcurrencyLimiter(searcher, max_concurrent=5)\n",
    "objective = tune.with_resources(\n",
    "    tune.with_parameters(run), resources={\"cpu\": 1, \"memory\": 400 * 1000000}\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    trainable=objective,\n",
    "    run_config=air.RunConfig(local_dir=\"./ray_results\"),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        search_alg=algo,\n",
    "        num_samples=N_ITER,\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_thesis_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
